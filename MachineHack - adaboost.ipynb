{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_excel('Data_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_excel('Data_Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7628 entries, 0 to 7627\n",
      "Data columns (total 2 columns):\n",
      "STORY      7628 non-null object\n",
      "SECTION    7628 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 119.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.copy(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_backslash_n(string):\n",
    "    string=string.replace('\\n',' ')\n",
    "    #while '  ' in string:\n",
    "        #string.replace('  ',' ')\n",
    "    return string\n",
    "\n",
    "def remove_extra(string):\n",
    "    if 'This story has been published from a wire agency feed without modifications to the text. Only the headline has been changed.' in string:\n",
    "        string = string.replace('This story has been published from a wire agency feed without modifications to the text. Only the headline has been changed.',' ')\n",
    "    if 'This story has been published from a wire agency feed without modifications to the text. Only the headline has been changed' in string:\n",
    "        string =  string.replace('This story has been published from a wire agency feed without modifications to the text. Only the headline has been changed',' ')\n",
    "    if 'story has been published from a wire agency feed without modifications to the text. Only the headline has been changed.' in string :\n",
    "        string = string.replace('story has been published from a wire agency feed without modifications to the text. Only the headline has been changed.',' ')\n",
    "\n",
    "        \n",
    "    return string\n",
    "    \n",
    "    \n",
    "\n",
    "df['STORY'] =df['STORY'].apply(fix_backslash_n)\n",
    "df['STORY'] =df['STORY'].apply(remove_extra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([5602,112,3744])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from num2words import num2words\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone',\n",
    "             'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount',\n",
    "             'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around',\n",
    "             'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before',\n",
    "             'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both',\n",
    "             'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de',\n",
    "             'describe', 'detail', 'did', 'do', 'does', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg',\n",
    "             'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone',\n",
    "             'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for',\n",
    "             'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had',\n",
    "             'has', 'hasnt', 'have', 'having', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed',\n",
    "             'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less',\n",
    "             'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly',\n",
    "             'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine',\n",
    "             'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once',\n",
    "             'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own',\n",
    "             'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed', 'seeming',\n",
    "             'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', \n",
    "             'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system',\n",
    "             't', 'take', 'ten', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there',\n",
    "             'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thickv', 'thin', 'third', 'this',\n",
    "             'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward',\n",
    "             'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we',\n",
    "             'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby',\n",
    "             'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom',\n",
    "             'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself',\n",
    "             'yourselves','said','The','As','By','A','In','But','He','She','They','Moreover','We','Its'\n",
    "             'There','there','However',\n",
    "             'While','His','With','An','The','This','So','On','Most','If'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(stop)\n",
    "stop = set(stop_words)\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    data = np.char.replace(data,\"’\",\"\")\n",
    "    data = np.char.replace(data, \"'\", \"\")\n",
    "    data = np.char.replace(data, \"‘\", \"\")\n",
    "    data = np.char.replace(data, \"—\", \"\")\n",
    "    data = np.char.replace(data,\"–\", \"\")\n",
    "    data = np.char.replace(data,\"”\",\"\")\n",
    "    return data\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    for i in (exclude):\n",
    "        data = np.char.replace(data, i, ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    data = np.char.replace(data, \"“\", \"\")\n",
    "    return data\n",
    "\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text\n",
    "\n",
    "def clean(data):\n",
    "    stop_free = \" \".join([i for i in data.split() if i not in stop])\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
    "    #y = processed.split()\n",
    "    return processed\n",
    "def tokenize_and_stem(text):\n",
    "   \n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STORY'] = df['STORY'].apply(remove_apostrophe)\n",
    "df['STORY'] = df['STORY'].apply(remove_punctuation)\n",
    "df['STORY'] = df['STORY'].apply(convert_numbers)\n",
    "df['STORY'] = df['STORY'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(x):\n",
    "    length = len(x)\n",
    "    res = len(x.split())\n",
    "    return res\n",
    "df['Word_Length'] = df['STORY'].apply(get_len)\n",
    "df = df[df['Word_Length']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='STORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "X=df['STORY']\n",
    "y = df['SECTION']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9480106100795755\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       411\n",
      "          1       0.95      0.94      0.94       678\n",
      "          2       0.96      0.94      0.95       488\n",
      "          3       0.95      0.94      0.95       308\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_adaboost = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "               ('tfidf', TfidfTransformer(norm='l2')),\n",
    "               ('truncatedSVD',TruncatedSVD(algorithm='randomized', n_components=500)),\n",
    "               ('ada', AdaBoostClassifier(n_estimators=500,\n",
    "                         learning_rate=1)),\n",
    "              ])\n",
    "model_adaboost.fit(X_train,y_train)\n",
    "model_adaboost_predict = model_adaboost.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(model_adaboost_predict, y_test))\n",
    "print(classification_report(y_test, model_adaboost_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9374005305039788\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.93      0.94      0.94       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_adaboost = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "               ('tfidf', TfidfTransformer(norm='l2')),\n",
    "               ('truncatedSVD',TruncatedSVD(algorithm='randomized', n_components=350)),\n",
    "               ('ada', AdaBoostClassifier(n_estimators=350,\n",
    "                         learning_rate=.1)),\n",
    "              ])\n",
    "model_adaboost.fit(X_train,y_train)\n",
    "model_adaboost_predict = model_adaboost.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(model_adaboost_predict, y_test))\n",
    "print(classification_report(y_test, model_adaboost_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9257294429708223\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.99      0.89      0.94       488\n",
      "          3       0.91      0.89      0.90       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9320954907161804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.91      0.95       488\n",
      "          3       0.91      0.91      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9246684350132626\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.91      0.93      0.92       678\n",
      "          2       0.98      0.88      0.93       488\n",
      "          3       0.90      0.91      0.90       308\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1885\n",
      "\n",
      "accuracy 0.9310344827586207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.94       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.91      0.94      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9315649867374005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.97      0.90      0.94       488\n",
      "          3       0.90      0.94      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9294429708222812\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.91      0.93      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9236074270557029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       411\n",
      "          1       0.92      0.92      0.92       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.91      0.92      0.91       308\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1885\n",
      "\n",
      "accuracy 0.9246684350132626\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.92      0.92       678\n",
      "          2       0.96      0.90      0.93       488\n",
      "          3       0.90      0.93      0.91       308\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1885\n",
      "\n",
      "accuracy 0.9352785145888595\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.93      0.93      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9262599469496021\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.99      0.89      0.94       488\n",
      "          3       0.91      0.89      0.90       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.929973474801061\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.90      0.92      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9347480106100796\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.98      0.91      0.95       488\n",
      "          3       0.90      0.93      0.91       308\n",
      "\n",
      "avg / total       0.94      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9331564986737401\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.89      0.94       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.929973474801061\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.91      0.91      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9320954907161804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.97      0.91      0.94       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9315649867374005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.93       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9331564986737401\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.97      0.90      0.94       488\n",
      "          3       0.91      0.93      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9411140583554377\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       411\n",
      "          1       0.94      0.94      0.94       678\n",
      "          2       0.96      0.93      0.94       488\n",
      "          3       0.93      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9278514588859417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.91      0.94      0.93       678\n",
      "          2       0.99      0.89      0.94       488\n",
      "          3       0.91      0.90      0.90       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9358090185676392\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.93      0.94      0.94       678\n",
      "          2       0.98      0.91      0.94       488\n",
      "          3       0.91      0.92      0.92       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9363395225464191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.89      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9326259946949602\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.90      0.93      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9331564986737401\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9289124668435014\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.93      0.92       678\n",
      "          2       0.97      0.90      0.93       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9326259946949602\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.97      0.89      0.93       488\n",
      "          3       0.93      0.94      0.93       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9294429708222812\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.91      0.93      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9336870026525199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.96      0.90      0.93       488\n",
      "          3       0.93      0.93      0.93       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9273209549071618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.99      0.89      0.94       488\n",
      "          3       0.91      0.89      0.90       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9305039787798408\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.89      0.94       488\n",
      "          3       0.91      0.92      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9310344827586207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.98      0.89      0.94       488\n",
      "          3       0.91      0.93      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9379310344827586\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.92      0.95      0.94       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.93      0.93      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9405835543766579\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.93      0.95      0.94       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.93      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9374005305039788\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.91      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9278514588859417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.97      0.89      0.93       488\n",
      "          3       0.92      0.91      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9363395225464191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.97      0.91      0.94       488\n",
      "          3       0.93      0.92      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9347480106100796\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.97      0.91      0.94       488\n",
      "          3       0.94      0.92      0.93       308\n",
      "\n",
      "avg / total       0.94      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9241379310344827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.91      0.88      0.90       308\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1885\n",
      "\n",
      "accuracy 0.9320954907161804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.90      0.91      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9358090185676392\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.94       411\n",
      "          1       0.92      0.95      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.93      0.92      0.92       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9379310344827586\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.93      0.94      0.94       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9358090185676392\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.91      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9379310344827586\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.91      0.94       488\n",
      "          3       0.92      0.93      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9336870026525199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.91      0.94      0.93       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.93      0.93      0.93       308\n",
      "\n",
      "avg / total       0.94      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9379310344827586\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.97      0.91      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9368700265251989\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.93      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9246684350132626\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.91      0.89      0.90       308\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1885\n",
      "\n",
      "accuracy 0.9283819628647215\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.91      0.93      0.92       678\n",
      "          2       0.98      0.89      0.94       488\n",
      "          3       0.90      0.91      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9347480106100796\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.91      0.93      0.92       308\n",
      "\n",
      "avg / total       0.94      0.93      0.93      1885\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9342175066312998\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.94       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.90      0.93       488\n",
      "          3       0.92      0.93      0.92       308\n",
      "\n",
      "avg / total       0.94      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9395225464190982\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.93      0.95      0.94       678\n",
      "          2       0.98      0.91      0.95       488\n",
      "          3       0.93      0.93      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9358090185676392\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.97      0.90      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9395225464190982\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.97      0.91      0.94       488\n",
      "          3       0.93      0.95      0.94       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9320954907161804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.94       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.97      0.91      0.94       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9320954907161804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.97      0.91      0.94       488\n",
      "          3       0.92      0.91      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9246684350132626\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.91      0.88      0.90       308\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1885\n",
      "\n",
      "accuracy 0.9320954907161804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.91      0.91      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9315649867374005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.89      0.94       488\n",
      "          3       0.92      0.91      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9363395225464191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9374005305039788\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.91      0.94       488\n",
      "          3       0.92      0.93      0.92       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9336870026525199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.93      0.93      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.91      0.94      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9368700265251989\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       411\n",
      "          1       0.93      0.94      0.93       678\n",
      "          2       0.98      0.91      0.94       488\n",
      "          3       0.92      0.94      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n",
      "accuracy 0.9331564986737401\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.96      0.90      0.93       488\n",
      "          3       0.92      0.93      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9315649867374005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.92      0.93      0.93       678\n",
      "          2       0.96      0.91      0.94       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9251989389920424\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       411\n",
      "          1       0.91      0.94      0.92       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.92      0.88      0.90       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9326259946949602\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.91      0.92      0.91       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9315649867374005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.90      0.94       488\n",
      "          3       0.91      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9326259946949602\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.98      0.89      0.93       488\n",
      "          3       0.92      0.92      0.92       308\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1885\n",
      "\n",
      "accuracy 0.9352785145888595\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       411\n",
      "          1       0.92      0.94      0.93       678\n",
      "          2       0.97      0.90      0.94       488\n",
      "          3       0.93      0.93      0.93       308\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1885\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-35f90c75ff16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                                  learning_rate=.1)),\n\u001b[0;32m     10\u001b[0m                       ])\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mmodel_adaboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mmodel_adaboost_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_adaboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \"\"\"\n\u001b[0;32m    472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ACU = []\n",
    "for x in range(100,1000,100):\n",
    "    for y in range(100,1000,100):\n",
    "        \n",
    "        model_adaboost = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2),)),\n",
    "                       ('tfidf', TfidfTransformer(norm='l2')),\n",
    "                       ('truncatedSVD',TruncatedSVD(algorithm='randomized', n_components=x)),\n",
    "                       ('ada', AdaBoostClassifier(n_estimators=y,\n",
    "                                 learning_rate=.1)),\n",
    "                      ])\n",
    "        model_adaboost.fit(X_train,y_train)\n",
    "        model_adaboost_predict = model_adaboost.predict(X_test)\n",
    "\n",
    "        print('accuracy %s' % accuracy_score(model_adaboost_predict, y_test))\n",
    "        print(classification_report(y_test, model_adaboost_predict))\n",
    "        ACU.append((x,y,accuracy_score(model_adaboost_predict, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-9639323e40d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAcu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mACU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "Acu = pd.Dataframe(ACU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
